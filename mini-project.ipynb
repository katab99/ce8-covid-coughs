{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Miniproject - Audio\n",
    "\n",
    "AVS 8th Semester - Group 841"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deeplearning/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "\n",
<<<<<<< HEAD
    "from datasets import load_dataset, DatasetDict,load_metric\n",
    "# https://huggingface.co/docs/transformers/main/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig\n",
    "# https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/trainer#transformers.TrainingArguments\n",
=======
    "from datasets import load_dataset, DatasetDict, load_metric\n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "from transformers import ASTFeatureExtractor, ASTForAudioClassification, ASTConfig, TrainingArguments, Trainer\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Parameters"
=======
    "#### Parameters"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "AUDIO_DIR = \"./data/\"\n",
    "CSV_DIR = \"./data/metadata_compiled.csv\"\n",
    "FILE_TYPE = \".mp3\"\n",
    "\n",
<<<<<<< HEAD
    "# Training Parameters\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 5e-4\n",
    "SAMPLING_RATE = 10000\n",
    "USE_PRETRAINED = False\n",
    "CHECKPOINT = 'MIT/ast-finetuned-audioset-10-10-0.4593' #Pre-trained weights\n",
    "#other weights can be found at https://huggingface.co/models?other=audio-spectrogram-transformer\n",
    "\n",
    "MAX_DURATION = 1\n",
    "NUM_CLASSES = 3\n",
    "HIDDEN_LAYER_SIZE = 768\n",
    "NUM_HIDDEN_LAYERS = 12\n",
    "MAX_SEQ_LENGTH = MAX_DURATION * SAMPLING_RATE\n",
    "MAX_FRAMES = 49\n",
    "MAX_EPOCHS = 2\n",
    "\n",
    "\n",
    "is_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
=======
    "# model\n",
    "SAMPLING_RATE = 16000\n",
    "BATCH_SIZE = 4 # 4\n",
    "LEARNING_RATE = 1e-3\n",
    "CHECKPOINT = 'MIT/ast-finetuned-audioset-10-10-0.4593'\n",
    "\n",
    "MAX_DURATION = 1\n",
    "NUM_CLASSES = 3\n",
    "HIDDEN_LAYER_SIZE = 384 # 768 \n",
    "NUM_HIDDEN_LAYERS = 12\n",
    "HIDDEN_DROPOUT_PROB = 0.1\n",
    "ATTENTION_DROPOUT_PROB = 0.1\n",
    "\n",
    "MAX_SEQ_LENGTH = MAX_DURATION * SAMPLING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### 1. Explore the dataset through code\n",
    "\n",
    "The csv file is loaded using pandas"
=======
    "#.csv file loading\n",
    "df = pd.read_csv(CSV_DIR)"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.csv file loading\n",
    "df = pd.read_csv(CSV_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many samples does the dataset contain?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": null,
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check no. samples\n",
    "print(f'Number of samples : {df.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. How many classes? How many samples per class? Show a histogram of the number of intances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of classes: {len(df[\"status\"].unique())}.\\n\\\n",
    "    Classes: {df[\"status\"].unique()}\\n\\\n",
    "    {pd.value_counts(df[\"status\"], dropna=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df['status'], dropna=False).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Play a random sample from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing healthy\n",
    "healthy = df[df['status'] == 'healthy'].sample()['uuid'].item()\n",
    "path = AUDIO_DIR + healthy + FILE_TYPE\n",
    "print(path)\n",
    "y, sr = torchaudio.load(path)\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing COVID-19\n",
    "covid = df[df['status'] == 'COVID-19'].sample()['uuid'].item()\n",
    "path = AUDIO_DIR + covid + FILE_TYPE\n",
    "y, sr = torchaudio.load(path)\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing symptomatic\n",
    "symptomatic = df[df['status'] == 'symptomatic'].sample()['uuid'].item()\n",
    "path =  AUDIO_DIR + symptomatic + FILE_TYPE\n",
    "y, sr = torchaudio.load(path)\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Describe if/how you think the data distribution will affect training of a classifier"
   ]
  },
  {
<<<<<<< HEAD
=======
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `healthy` data is over represented among the ohter classes, the model after training can összetéveszteni confuse `COVID-19` and `symptomatic`  "
   ]
  },
  {
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Decide what part of the dataset to use; all, some classes, some samples. Motivate your choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use the data without labels as we cannot check if those classification would be correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Audio Spectogram Transformer Implementation\n",
    "\n",
    "This project uses the huggingface library to train the AST model on the cough dataset!"
=======
    "#### 2. Use a neural network of your own chose to classify the dataset. Explain your choice and at least one alternative. Document your experiences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to train the dataset with `Audio Spectogram Transformer` model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "##### Load soundfiles into dataset"
=======
    "Load soundfiles into dataset"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 16226/16226 [00:00<00:00, 26404.15it/s]\n",
      "Found cached dataset audiofolder (/home/ubuntu/.cache/huggingface/datasets/audiofolder/default-5813fa48534e5405/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "# must have metadata.csv with 'file_name' column to have also the features\n",
    "# unsplitted dataset\n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "dataset = load_dataset(\"audiofolder\", data_dir=AUDIO_DIR, split=\"train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "The dataset is split into {Training 70%, Valid 20%, Test 10%}"
=======
    "Split up the data : `training` - 70%, `validation` - 20%, `test` - 10%"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "#We can not split directly to train, valid and test so we do some hacking!\n",
    "train_testvalid = dataset.train_test_split(test_size=0.3) #Split dataset into train 70% and test 30%\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=1/3) #Split the splitted dataset into valid and test\n",
=======
    "train_testvalid = dataset.train_test_split(test_size=0.3)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=1/3)\n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "\n",
    "dataset = DatasetDict({\n",
    "    'train' : train_testvalid['train'],\n",
    "    'test' : test_valid['test'],\n",
    "    'valid' : test_valid['train']\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "A dictionary is created that stores the class labels and a corresponding number 0,1,2\n",
    "\n",
    "Healthy = 0\n",
    "\n",
    "Covid-19 = 1\n",
    "\n",
    "Symptomatic = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'healthy': '0', 'COVID-19': '1', 'symptomatic': '2'}\n"
     ]
    }
   ],
   "source": [
    "# getting the labels for classification\n",
    "labels = list(df[\"status\"].unique()[1:])\n",
    "\n",
    "#A dictionary is created that stores the class and a corresponding number 0, 1, 2.\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "print(label2id)"
=======
    "List the labels from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the labels for classification\n",
    "labels = list(df[\"status\"].unique()[1:])\n",
    "\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model and Feature Extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if you want to use `random weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ASTConfig(\n",
    "    hidden_size=768, # default : 768\n",
    "    #num_hidden_layers=12, # default : 12\n",
    "    hidden_dropout_prob= 0.0, # def.: 0.0\n",
    "    attention_probs_dropout_prob=0.0 # def.: 0.0\n",
    ")\n",
    "\n",
    "# input normalization: mean = 0, std = 0.5\n",
    "feature_extractor = ASTFeatureExtractor(config, sampling_rate=SAMPLING_RATE, num_mel_bins=32, mean=0, std=0.5)\n",
    "\n",
    "model = ASTForAudioClassification(config)\n",
    "# weights must be the same for the model and the tokenizer/feature extractor "
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "##### Creating the AST Model\n",
    "\n",
    "This cell instantiates the model using random weights or pretrained weights using the USE_PRETRAINED hyperparameter.\n",
    "\n",
    "The pretrained weights use weights from the CHECKPOINT hyperparamter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model with random weights!\n"
     ]
    }
   ],
   "source": [
    "if USE_PRETRAINED == False:\n",
    "    print(\"Loading a model with random weights!\")\n",
    "    # use this for [RANDOM WEIGHTS] - no pretraining\n",
    "    config = ASTConfig(\n",
    "        hidden_size=HIDDEN_LAYER_SIZE, # default : 768\n",
    "        num_hidden_layers=NUM_HIDDEN_LAYERS, # default : 12\n",
    "        hidden_dropout_prob= 0.0, # def.: 0.0\n",
    "        attention_probs_dropout_prob=0.0 # def.: 0.0\n",
    "    )\n",
    "\n",
    "    # basically tokenizer\n",
    "    # input normalization: mean = 0, std = 0.5\n",
    "    feature_extractor = ASTFeatureExtractor(config, sampling_rate=SAMPLING_RATE, num_mel_bins=32, mean=0, std=0.5)\n",
    "\n",
    "    model = ASTForAudioClassification(config)\n",
    "    # weights must be the same for the model and the tokenizer/feature extractor \n",
    "else:\n",
    "    print(\"Loading a model with pre-trained weights from: \", CHECKPOINT)\n",
    "   # feature extractor and model\n",
    "    feature_extractor = ASTFeatureExtractor(\n",
    "        CHECKPOINT\n",
    "    )\n",
    "\n",
    "    model = ASTForAudioClassification.from_pretrained(\n",
    "        CHECKPOINT, \n",
    "        num_labels=NUM_CLASSES,\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        ignore_mismatched_sizes=True\n",
    "        ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing dataset"
=======
    "Run this cell if you want to use `pre-trained weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ASTConfig(\n",
    "    hidden_size=HIDDEN_LAYER_SIZE, # default : 768\n",
    "    #num_hidden_layers=NUM_HIDDEN_LAYERS, # default : 12\n",
    "    hidden_dropout_prob=HIDDEN_DROPOUT_PROB, # def.: 0.0\n",
    "    attention_probs_dropout_prob=ATTENTION_DROPOUT_PROB, # def.: 0.0\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")\n",
    "\n",
    "feature_extractor = ASTFeatureExtractor(\n",
    "    CHECKPOINT\n",
    ")\n",
    "\n",
    "model = ASTForAudioClassification.from_pretrained(\n",
    "    CHECKPOINT, \n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(labels),\n",
    "label2id=label2id,\n",
    "id2label=id2label,\n",
    "ignore_mismatched_sizes=True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for `map`"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map function\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "def preprocess(examples):\n",
    "    audio_arr = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arr,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    label = [int(label2id[x]) for x in examples[\"label\"]]\n",
    "    \n",
    "    inputs[\"label\"] = label\n",
    "    return inputs\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Preprocessing the data! This takes time so only perform this once!"
=======
    "Tokenizing the dataset"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": null,
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# mapping datasets -> feature extraction\n",
    "train_ = dataset['train'].map(preprocess, remove_columns=[\"audio\"], batched=True)\n",
    "valid_ = dataset['valid'].map(preprocess, remove_columns=[\"audio\"], batched=True)\n",
    "test_ = dataset['test'].map(preprocess, remove_columns=[\"audio\"], batched=True)"
=======
    "dataset['train'] = dataset['train'].map(preprocess, remove_columns=[\"audio\"], batched=True)\n",
    "dataset['valid'] = dataset['valid'].map(preprocess, remove_columns=[\"audio\"], batched=True)\n",
    "dataset['test']= dataset['test'].map(preprocess, remove_columns=[\"audio\"], batched=True)"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Setting up the optimizer and scheduler!"
=======
    "### Training the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `optimizer` and `scheduler`"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
<<<<<<< HEAD
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
=======
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=30, gamma=0.1)"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Defining a function for computing the metrics!"
=======
    "Metric computing function : calculates `accuracy`, `precision`, `recall` and `f1 score`"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": null,
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    metrics = dict()\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy_metric = load_metric('accuracy')\n",
    "    precision_metric = load_metric('precision')\n",
    "    recall_metric = load_metric('recall')\n",
    "    f1_metric = load_metric('f1')\n",
    "\n",
    "    metrics.update(accuracy_metric.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(precision_metric.compute(predictions=predictions, references=labels, average='weighted'))\n",
    "    metrics.update(recall_metric.compute(predictions=predictions, references=labels, average='weighted'))\n",
    "    metrics.update(f1_metric.compute(predictions=predictions, references=labels, average='weighted'))\n",
<<<<<<< HEAD
=======
    "\n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "    return metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Setting up wandb"
=======
    "Setting up `wandb` to visualize training results"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": null,
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_4016667/4057967727.py 10 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1144, in init\n",
      "    run = wi.init()\n",
      "  File \"/home/ubuntu/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 773, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: Error communicating with wandb process, exiting...\n",
      "For more info see: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1144\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1145\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:773\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m run_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mCommError\u001b[0m: Error communicating with wandb process, exiting...\nFor more info see: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# turn off watch to log faster\u001b[39;00m\n\u001b[1;32m      8\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mWANDB_WATCH\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfalse\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m wandb\u001b[39m.\u001b[39;49minit(settings\u001b[39m=\u001b[39;49mwandb\u001b[39m.\u001b[39;49mSettings(start_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfork\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1181\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[39mif\u001b[39;00m except_exit:\n\u001b[1;32m   1180\u001b[0m             os\u001b[39m.\u001b[39m_exit(\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1181\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror_seen\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_PROJECT\"]=\"cough-project\"\n",
    "\n",
    "# save your trained model checkpoint to wandb\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "\n",
    "# turn off watch to log faster\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = 'bcedb36b3b18e0036691776ac131e3ea65b3da02'\n",
    "\n",
    "wandb.init(settings=wandb.Settings(start_method=\"fork\"))\n",
    "wandb.run.name = 'ok-boomer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining `TrainingArguments` and `Trainer`"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
=======
   "execution_count": null,
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hyperparams for Trainer\n",
    "training_arg = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    report_to=\"wandb\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
<<<<<<< HEAD
    "    #num_train_epochs= max_epochs,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    max_steps=1300,\n",
    "    logging_steps=100,\n",
    "    eval_steps=500, \n",
=======
    "    #num_train_epochs= MAX_APOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    max_steps=1000, \n",
    "    logging_steps=50,\n",
    "    eval_steps=200, \n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    "    eval_accumulation_steps=1, \n",
    "    load_best_model_at_end=True,\n",
    "    warmup_steps=50,\n",
    "    save_total_limit=2,\n",
    "    #metric_for_best_model='accuracy'\n",
    "    )\n",
    "\n",
    "# defining trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arg,\n",
<<<<<<< HEAD
    "    train_dataset=train_,\n",
    "    eval_dataset=valid_,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=[optimizer,scheduler]\n",
=======
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['valid'],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler)\n",
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
    ")"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /home/ubuntu/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/integrations.py 727 setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1144, in init\n",
      "    run = wi.init()\n",
      "  File \"/home/ubuntu/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 773, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: Error communicating with wandb process, exiting...\n",
      "For more info see: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1144\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1145\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:773\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m run_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mCommError\u001b[0m: Error communicating with wandb process, exiting...\nFor more info see: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# training session\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1638\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/trainer.py:1818\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step\n\u001b[1;32m   1816\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1818\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_handler\u001b[39m.\u001b[39;49mon_train_begin(args, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrol)\n\u001b[1;32m   1820\u001b[0m \u001b[39m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   1821\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mignore_data_skip:\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/trainer_callback.py:353\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    352\u001b[0m     control\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_train_begin\u001b[39;49m\u001b[39m\"\u001b[39;49m, args, state, control)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/trainer_callback.py:397\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_event\u001b[39m(\u001b[39mself\u001b[39m, event, args, state, control, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    396\u001b[0m     \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 397\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(callback, event)(\n\u001b[1;32m    398\u001b[0m             args,\n\u001b[1;32m    399\u001b[0m             state,\n\u001b[1;32m    400\u001b[0m             control,\n\u001b[1;32m    401\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    402\u001b[0m             tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[1;32m    403\u001b[0m             optimizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer,\n\u001b[1;32m    404\u001b[0m             lr_scheduler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_scheduler,\n\u001b[1;32m    405\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    406\u001b[0m             eval_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_dataloader,\n\u001b[1;32m    407\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[39m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/integrations.py:753\u001b[0m, in \u001b[0;36mWandbCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m     args\u001b[39m.\u001b[39mrun_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n\u001b[0;32m--> 753\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(args, state, model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/transformers/integrations.py:727\u001b[0m, in \u001b[0;36mWandbCallback.setup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m         init_args[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mrun_name\n\u001b[1;32m    726\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mrun \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wandb\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m    728\u001b[0m         project\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mWANDB_PROJECT\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhuggingface\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    729\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_args,\n\u001b[1;32m    730\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[39m# add config parameters (run may have been created manually)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(combined_dict, allow_val_change\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1181\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[39mif\u001b[39;00m except_exit:\n\u001b[1;32m   1180\u001b[0m             os\u001b[39m.\u001b[39m_exit(\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1181\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror_seen\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
=======
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   "source": [
    "Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# evaluation\n",
    "predictions = trainer.predict(test_)"
=======
    "#### Testing the training"
>>>>>>> 0cd504428e041ad4b61926bf09d27be3402f9cf3
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "predictions = trainer.predict(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model weigths into files\n",
    "model.save_pretrained('./saved_model/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Discuss at least four relevant hyper-parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate : \\\n",
    "Epoch Numer : \\\n",
    "Batch Size : \\\n",
    "Optimizer: \\\n",
    "Layer Number : [??]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "# epoch number\n",
    "# mini-batch size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Experiment with the effect of different batch sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Experiment with the effect of different learning rates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Experiment with different number of network layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Implement at least two data agumentation techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Discuss what influences the memory use of a solution such as yours. What can be done to reduce this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3f78a94c79aa2b4cde3db52c6d7f9e98cfa173f2ab20b939f1d7db0be852c82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
